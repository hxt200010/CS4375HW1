# -*- coding: utf-8 -*-
"""HW4375LAB1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mln3rId9zsr_Y54eFf2WbgZvz9YPM_me
"""

import numpy as np
import pandas as pd
import seaborn as sb
import sklearn
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')

# Read the data into a DataFrame
df =pd.read_csv("https://raw.githubusercontent.com/hxt200010/CS4375HW1/main/student-por.csv")

# List of binary column names
binary_columns = ['schoolsup', 'famsup', 'paid', 'activities','nursery', 'higher','internet','romantic']

# Apply label encoding to each binary column
for column in binary_columns:
    df[column] = df[column].map({'yes': 1, 'no': 0})

df.head(100)

#Pulling correlations to see if y are correlstions within the dataframe
df.corr()

#After the correlation, the outcome G3: final grade has strong correlation with G1& G2
X = df[['G1', 'G2']]  # Use only G1 and G2 as features
y = df['G3']

X

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(y_test.isnull().sum())  # If y_test is a pandas Series or DataFrame
# OR
print(np.isnan(y_test).sum())  # If y_test is a numpy array

import random
def initialize(dim):
  b=random.random()
  theta=np.random.rand(dim)
  return b,theta

b,theta=initialize(2)
print("Bias: ",b,"Weights: ",theta)

def predict_Y(b,theta,X):
  return b + np.dot(X,theta)
Y_hat=predict_Y(b,theta,X_train)
Y_hat[0:10]

import math
def get_cost(Y,Y_hat):
  Y_resd=Y-Y_hat
  return np.sum(np.dot(Y_resd.T,Y_resd))/len(Y-Y_resd)
Y_hat=predict_Y(b,theta,X_train)
get_cost(y_train,Y_hat)

def update_theta(x,y,y_hat,b_0,theta_o,learning_rate):
  db=(np.sum(y_hat-y)*2)/len(y)
  dw=(np.dot((y_hat-y),x)*2)/len(y)
  b_1=b_0-learning_rate*db
  theta_1=theta_o-learning_rate*dw
  return b_1,theta_1
print("After initialization -Bias: ",b,"theta: ",theta)
Y_hat=predict_Y(b,theta,X_train)
b,theta=update_theta(X_train,y_train,Y_hat,b,theta,0.01)
print("After first update -Bias: ",b,"theta: ",theta)
get_cost(y_train,Y_hat)

import pandas as pd

def run_gradient_descent(X, Y, alpha, num_iterations):
    b, theta = initialize(X.shape[1])
    iter_num = 0
    gd_iterations_df = pd.DataFrame(columns=['iteration', 'cost'])
    result_idx = 0

    for each_iter in range(num_iterations):
        Y_hat = predict_Y(b, theta, X)
        this_cost = get_cost(Y, Y_hat)
        prev_b = b
        prev_theta = theta
        b, theta = update_theta(X, Y, Y_hat, prev_b, prev_theta, alpha)

        if iter_num % 10 == 0:
            gd_iterations_df.loc[result_idx] = [iter_num, this_cost]
            result_idx = result_idx + 1

        iter_num += 1

    print("Final Estimate of b and theta:", b, theta)

    return gd_iterations_df, b, theta

# Call the function with your data and parameters
gd_iterations_df, b, theta = run_gradient_descent(X_train, y_train, alpha=0.001, num_iterations=200)

# Display the first 10 rows of gd_iterations_df
print(gd_iterations_df.head(10))

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.plot(gd_iterations_df['iteration'], gd_iterations_df['cost'])
plt.xlabel("Number of iterations")
plt.ylabel("Cost or MSE")

def predict_linear_regression(b, theta, X):
    return b + np.dot(X, theta)

# Predict the test set
y_predicted = predict_linear_regression(b, theta, X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_test, y_predicted)
mse = mean_squared_error(y_test, y_predicted)
r2 = r2_score(y_test, y_predicted)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

import matplotlib.pyplot as plt

# Create a scatter plot for the actual values (test set)
plt.scatter(range(len(y_test)), y_test, label='Actual', color='blue', marker='o')

# Create a line plot for the predicted values
#plt.plot(range(len(y_test)), y_predicted, label='Predicted', color='red', linestyle='--')
plt.scatter(range(len(y_test)), y_predicted, label='Predict', color='red', marker='x')

plt.xlabel('Data Point')
plt.ylabel('Value')
plt.title('Actual vs. Predicted Values')
plt.legend()
plt.show()

